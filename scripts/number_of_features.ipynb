{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_processing_thsis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import libiraries for data processing**"
      ],
      "metadata": {
        "id": "lX8wm5e0PGcI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_xOQ5GMVOtG5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import  DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from xgboost import cv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lo_Q6zWfl2R",
        "outputId": "8cf63527-0c6e-44e1-8bf5-42769b8baea8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cinfusion matrix function and top feature selector; needed functions.**"
      ],
      "metadata": {
        "id": "RbrS74dwPknp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' <<mean_conf>> simply gets the mean of each element in confiusion matrixs \n",
        "    which are the outcome in each k-subset cross validaion.\n",
        "    \n",
        "    return: mean of all confision matrics\n",
        "'''\n",
        "def mean_conf(confusion_matrix):\n",
        "    # empty lists to fill up every elements of the different confusion matrics\n",
        "    e1, e2, e3, e4 = [], [], [], []\n",
        "    for i in range(0,len(confusion_matrix)):\n",
        "        e1.append(confusion_matrix[i][0][0])\n",
        "        e2.append(confusion_matrix[i][0][1])\n",
        "        e3.append(confusion_matrix[i][1][0])\n",
        "        e4.append(confusion_matrix[i][1][1])\n",
        "    # getting mean of each element\n",
        "    mean_matrix = [[round(np.mean(e1)), round(np.mean(e2))],\n",
        "                   [round(np.mean(e3)), round(np.mean(e4))]]\n",
        "    return mean_matrix\n",
        "    \n",
        "    \n",
        "''' <<to_features>> finds common top i features (by XGBoost classifier) and \n",
        "    return them as a dictionary of string which are the name of the features. \n",
        "    df: dataframe as an input\n",
        "    i: number of features needed to be ranked\n",
        "    \n",
        "    return: the list of i top ranked features\n",
        "'''\n",
        "def top_features(df,i):\n",
        "    # defining the target value and separate it\n",
        "    y = df['MGMT_value']\n",
        "    X = df.drop(['MGMT_value','Unnamed: 0'], axis = 1)\n",
        "    \n",
        "    kf = KFold(n_splits=5, shuffle=True)\n",
        "    for train_index , test_index in kf.split(X):\n",
        "        X_train , X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
        "        y_train , y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        \n",
        "        # declare parameters\n",
        "        params = {\n",
        "                    'objective':'binary:logistic',\n",
        "                    'max_depth': 4,\n",
        "                    'alpha': 10,\n",
        "                    'learning_rate': 1.0,\n",
        "                    'n_estimators':100\n",
        "                }\n",
        "        \n",
        "        # instantiate the classifier \n",
        "        xgb_clf = XGBClassifier(**params)\n",
        "        \n",
        "        # fit the classifier to the training data\n",
        "        xgb_clf.fit(X_train, y_train)\n",
        "        \n",
        "        # list of features name\n",
        "        feat_names = list(X_train.columns)\n",
        "        \n",
        "        feats = {} # a dict to hold feature_name: feature_importance\n",
        "        for feature, importance in zip(feat_names, xgb_clf.feature_importances_):\n",
        "            feats[feature] = importance #add the name/value pair \n",
        "        # appending the dictionary of features with their scores by each k subset\n",
        "        feats.update({x:y for x,y in feats.items() if y!=0})\n",
        "        \n",
        "    # sort the features based on their importance\n",
        "    im_feat = sorted(feats.items(), key=lambda feats: feats[1], reverse=True)[:i]\n",
        "    im_feat.sort(key = lambda x: x[1], reverse=True)\n",
        "    im_feat = [item for sublist in im_feat for item in sublist]\n",
        "    im_feat = [elm for elm in im_feat if isinstance(elm, str)]\n",
        "    \n",
        "    # the list of most i-th top ranked features\n",
        "    return im_feat"
      ],
      "metadata": {
        "id": "rBOmnPyiPean"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAIN PART:"
      ],
      "metadata": {
        "id": "BgFPNLqLfUXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% main part\n",
        "''' Splitting the dataset and applying k-fold cross validation\n",
        "    Feature selection by XGBoost method\n",
        "    Fitting different model: SVM, LogisticRegression, Random forest, NN\n",
        "    Changing the numbere of features to see the idieal number\n",
        "'''\n",
        "# defining a new empty dataframe to fill with different metrics\n",
        "metrics = pd.DataFrame(columns=['features_number','mean_accuracy_NN', 'std_accuracy_NN',\n",
        "                                'mean_f1score_NN', 'std_f1score_NN', 'confusion_NN',\n",
        "                                'mean_accuracy_SVM', 'std_accuracy_SVM',\n",
        "                                'mean_f1score_SVM', 'std_f1score_SVM', 'confusion_SVM',\n",
        "                                'mean_accuracy_LR', 'std_accuracy_LR',\n",
        "                                'mean_f1score_LR', 'std_f1score_LR', 'confusion_LR',\n",
        "                                'mean_accuracy_MLP', 'std_accuracy_MLP',\n",
        "                                'mean_f1score_MLP', 'std_f1score_MLP', 'confusion_MLP'])\n",
        "\n",
        "# defining a new empty dataframe for filling best parameters in each iteration\n",
        "parameters = pd.DataFrame(columns=['features_number','Nearest Neighbor',\n",
        "                                  'Support Vector Machine', 'Logistic Regresion',\n",
        "                                  'Multi-layer Perceptron'])\n",
        "\n",
        "# copy the dataframe for mean and std of metrics\n",
        "train_metrics = metrics.copy()\n",
        "test_metrics = metrics.copy()\n",
        "\n",
        "# reading and splitting the edataset into train and test \n",
        "df = pd.read_csv('/content/drive/MyDrive/data/all_t2_data.csv')\n",
        "\n",
        "# defining the target value and separate it \n",
        "y = df['MGMT_value']\n",
        "X = df.drop(['MGMT_value', 'Unnamed: 0'], axis = 1)\n",
        "\n",
        "# getting the top features\n",
        "list_im_feat = top_features(df, 20)\n",
        "\n",
        "# dataset with best features\n",
        "X = X[list_im_feat].copy()\n",
        "\n",
        "# splitting the whole dataset into train (80%) and test (20%)\n",
        "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# transform data: final test\n",
        "scaler = MinMaxScaler()\n",
        "X_ts = scaler.fit_transform(X_ts)\n",
        "\n",
        "# convert the test set to the dataframe in order to use it in the while loop\n",
        "X_ts = pd.DataFrame(X_ts, columns = X_tr.columns)\n",
        "\n",
        "# applying k-fold cross validation (K=10) --> outer loop\n",
        "cv_outer = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "# iteration over number of features i\n",
        "i = 20\n",
        "while i!=0:\n",
        "    \n",
        "    # defining performance metrics lists for training\n",
        "    conf_NN_tr, conf_SVM_tr, conf_LR_tr, conf_MLP_tr = [], [], [], []\n",
        "    acc_NN_tr, acc_SVM_tr, acc_LR_tr, acc_MLP_tr = [], [], [], []\n",
        "    f1_NN_tr, f1_SVM_tr, f1_LR_tr, f1_MLP_tr = [], [], [], []\n",
        "    \n",
        "    # defining performance metrics lists for test\n",
        "    conf_NN_ts, conf_SVM_ts, conf_LR_ts, conf_MLP_ts = [], [], [], []\n",
        "    acc_NN_ts, acc_SVM_ts, acc_LR_ts, acc_MLP_ts = [], [], [], []\n",
        "    f1_NN_ts, f1_SVM_ts, f1_LR_ts, f1_MLP_ts = [], [], [], []\n",
        "    \n",
        "    # defining best paramters list to store for traing\\test\n",
        "    best_par_NN, best_par_SVM, best_par_LR, best_par_MLP= [], [], [], []\n",
        "    \n",
        "    # configuring thee cross-validation outer loop\n",
        "    for train_index , test_index in cv_outer.split(X_tr):\n",
        "        X_train , X_test = X_tr.iloc[train_index,:], X_tr.iloc[test_index,:]\n",
        "        y_train , y_test = y_tr.iloc[train_index], y_tr.iloc[test_index]\n",
        "        \n",
        "        # configuring the cross-validation procedure (inner loop)\n",
        "        cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
        "        \n",
        "        # keep the most top i ranked features\n",
        "        X_train = X_train[list_im_feat[:i]].copy()\n",
        "        X_test = X_test[list_im_feat[:i]].copy() \n",
        "        X_ts = X_ts[list_im_feat[:i]].copy()\n",
        "        \n",
        "        # transform data\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.fit_transform(X_test) \n",
        "          \n",
        "        #%% Nearst neighbor:\n",
        "        # Create and train the KNeighborsClassifier on the train\\test set\n",
        "        model_NN = KNeighborsClassifier()\n",
        "        \n",
        "        # Set up possible values of parameters to optimize over\n",
        "        parameters_NN = {'n_neighbors' :[3, 5, 11, 19],\n",
        "                         'weights':['ubiform', 'distance'],\n",
        "                         'metric':['euclidean', 'manhattan']}\n",
        "        \n",
        "        # define search\n",
        "        classifier_NN = GridSearchCV(model_NN, parameters_NN, scoring='accuracy', cv=cv_inner, refit=True)\n",
        "        \n",
        "        # execute search\n",
        "        result_NN = classifier_NN.fit(X_train, y_train)\n",
        "        \n",
        "        # get the best performing model fit on the whole training\\test set + save the best parameters\n",
        "        best_model_NN = result_NN.best_estimator_\n",
        "        best_par_NN.append(classifier_NN.best_params_)\n",
        "        \n",
        "        # make a prediction on the validation set and then check model performance (train)\n",
        "        y_pred_NN = best_model_NN.predict(X_train)\n",
        "        \n",
        "        acc_NN_tr.append(accuracy_score(y_train, y_pred_NN))\n",
        "        conf_NN_tr.append(confusion_matrix(y_train, y_pred_NN, normalize='true'))\n",
        "        f1_NN_tr.append(f1_score(y_train, y_pred_NN))\n",
        "        \n",
        "        # make a prediction on the validation set and then check model performance (test)\n",
        "        y_pred_NN = best_model_NN.predict(X_ts)\n",
        "        \n",
        "        acc_NN_ts.append(accuracy_score(y_ts, y_pred_NN))\n",
        "        conf_NN_ts.append(confusion_matrix(y_ts, y_pred_NN, normalize='true'))\n",
        "        f1_NN_ts.append(f1_score(y_ts, y_pred_NN))\n",
        "        \n",
        "        #%% Support Vector Machine:\n",
        "        # build the SVM classifier and train it on the entire training\\test data set\n",
        "        model_SVM = SVC()\n",
        "        \n",
        "        # Set up possible values of parameters to optimize over\n",
        "        parameters_SVM = {'C': [0.1, 1, 10, 100, 1000],\n",
        "                          'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "                          'kernel': ['rbf', 'poly', 'sigmoid']}\n",
        "        \n",
        "        # define search\n",
        "        classifier_SVM = GridSearchCV(model_SVM, parameters_SVM, scoring='accuracy', cv=cv_inner, refit=True)\n",
        "        \n",
        "        # execute search\n",
        "        result_SVM = classifier_SVM.fit(X_train, y_train)\n",
        "        \n",
        "        # get the best performing model fit on the whole training\\test set + save the best parameters\n",
        "        best_model_SVM = result_SVM.best_estimator_\n",
        "        best_par_SVM.append(classifier_SVM.best_params_)\n",
        "        \n",
        "        # get predictions on the test set and store the performance metrics (train)\n",
        "        y_pred_SVC = best_model_SVM.predict(X_train)\n",
        "        \n",
        "        acc_SVM_tr.append(accuracy_score(y_train, y_pred_SVC))\n",
        "        conf_SVM_tr.append(confusion_matrix(y_train, y_pred_SVC, normalize='true'))\n",
        "        f1_SVM_tr.append(f1_score(y_train, y_pred_SVC))\n",
        "        \n",
        "        # get predictions on the test set and store the performance metrics (test)\n",
        "        y_pred_SVC = best_model_SVM.predict(X_ts)\n",
        "        \n",
        "        acc_SVM_ts.append(accuracy_score(y_ts, y_pred_SVC))\n",
        "        conf_SVM_ts.append(confusion_matrix(y_ts, y_pred_SVC, normalize='true'))\n",
        "        f1_SVM_ts.append(f1_score(y_ts, y_pred_SVC))\n",
        "\n",
        "    \n",
        "        #%% Logistic Regession:\n",
        "        # build the classifier and fit the model\n",
        "        model_LR = LogisticRegression()\n",
        "        \n",
        "        # Set up possible values of parameters to optimize over\n",
        "        parameters_LR = {'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
        "                         'C': [0.001,.009,0.01,.09,1,5,10,25,50,75,100],\n",
        "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']}\n",
        "        \n",
        "        # define search\n",
        "        classifier_LR = GridSearchCV(model_LR, parameters_LR, scoring='accuracy', cv=cv_inner, refit=True)\n",
        "        \n",
        "        # execute search\n",
        "        result_LR = classifier_LR.fit(X_train, y_train)\n",
        "        \n",
        "        # get the best performing model fit on the whole training set + save the best parameters\n",
        "        best_model_LR = result_LR.best_estimator_\n",
        "        best_par_LR.append(classifier_LR.best_params_)\n",
        "        \n",
        "        # prediction and store performance metrics (train)\n",
        "        y_pred_LR = best_model_LR.predict(X_train)\n",
        "        \n",
        "        acc_LR_tr.append(accuracy_score(y_train, y_pred_LR))\n",
        "        conf_LR_tr.append(confusion_matrix(y_train, y_pred_LR, normalize='true'))\n",
        "        f1_LR_tr.append(f1_score(y_train, y_pred_LR))\n",
        "        \n",
        "        # prediction and store performance metrics (test)\n",
        "        y_pred_LR = best_model_LR.predict(X_ts)\n",
        "        \n",
        "        acc_LR_ts.append(accuracy_score(y_ts, y_pred_LR))\n",
        "        conf_LR_ts.append(confusion_matrix(y_ts, y_pred_LR, normalize='true'))\n",
        "        f1_LR_ts.append(f1_score(y_ts, y_pred_LR))\n",
        "\n",
        "        \n",
        "        #%% Neural Network:\n",
        "        # create a MLPClassifier and fit the model\n",
        "        model_MPL = MLPClassifier(solver='lbfgs', \n",
        "                        alpha=1e-5,\n",
        "                        hidden_layer_sizes=(6,), \n",
        "                        random_state=1)\n",
        "        \n",
        "        # Set up possible values of parameters to optimize over\n",
        "        parameters_MLP = {'batch_size': [256],\n",
        "                          'momentum': [0.9, 0.99 ],\n",
        "                          'learning_rate_init':[0.001, 0.01, 0.1],\n",
        "                          'solver': ['adam'],\n",
        "                          'alpha': [0.0001, 0.05],\n",
        "                          'learning_rate': ['constant','adaptive']}\n",
        "        \n",
        "        # define search\n",
        "        classifier_MLP = GridSearchCV(model_MPL, parameters_MLP, scoring='accuracy', cv=cv_inner, refit=True)\n",
        "        \n",
        "        # execute search\n",
        "        result_MLP = classifier_MLP.fit(X_train, y_train)\n",
        "        \n",
        "        # get the best performing model fit on the whole training set + save the best parameters\n",
        "        best_model_MLP = result_MLP.best_estimator_\n",
        "        best_par_MLP.append(classifier_MLP.best_params_)\n",
        "        \n",
        "        # prediction and store preformance metrics (train)\n",
        "        y_pred_NN = best_model_MLP.predict(X_train)\n",
        "    \n",
        "        acc_MLP_tr.append(accuracy_score(y_train, y_pred_NN))\n",
        "        conf_MLP_tr.append(confusion_matrix(y_train, y_pred_NN, normalize='true'))\n",
        "        f1_MLP_tr.append(f1_score(y_train, y_pred_NN))\n",
        "        \n",
        "        # prediction and store preformance metrics (test)\n",
        "        y_pred_NN = best_model_MLP.predict(X_ts)\n",
        "    \n",
        "        acc_MLP_ts.append(accuracy_score(y_ts, y_pred_NN))\n",
        "        conf_MLP_ts.append(confusion_matrix(y_ts, y_pred_NN, normalize='true'))\n",
        "        f1_MLP_ts.append(f1_score(y_ts, y_pred_NN))\n",
        "\n",
        "        \n",
        "    \n",
        "    # storing result of evaluation metrics in dataframe for furthre anlysis\n",
        "    # trainging results\n",
        "    train_data_to_store = {'features_number':f'{i}' ,'mean_accuracy_NN': np.mean(acc_NN_tr), 'std_accuracy_NN':np.std(acc_NN_tr),\n",
        "                          'mean_f1score_NN':np.mean(f1_NN_tr) , 'std_f1score_NN':np.std(f1_NN_tr), 'confusion_NN':mean_conf(conf_NN_tr),\n",
        "                          'mean_accuracy_SVM':np.mean(acc_SVM_tr), 'std_accuracy_SVM':np.std(acc_SVM_tr),\n",
        "                          'mean_f1score_SVM':np.mean(f1_SVM_tr), 'std_f1score_SVM':np.std(f1_SVM_tr), 'confusion_SVM':mean_conf(conf_SVM_tr),\n",
        "                          'mean_accuracy_LR':np.mean(acc_LR_tr), 'std_accuracy_LR':np.std(acc_LR_tr),\n",
        "                          'mean_f1score_LR':np.mean(f1_LR_tr), 'std_f1score_LR':np.std(f1_LR_tr), 'confusion_LR':mean_conf(conf_LR_tr),\n",
        "                          'mean_accuracy_MLP':np.mean(acc_MLP_tr), 'std_accuracy_MLP':np.std(acc_MLP_tr),\n",
        "                          'mean_f1score_MLP':np.mean(f1_MLP_tr), 'std_f1score_MLP':np.std(f1_MLP_tr), 'confusion_MLP':mean_conf(conf_MLP_tr)}\n",
        "    \n",
        "    # test results\n",
        "    test_data_to_store = {'features_number':f'{i}' ,'mean_accuracy_NN': np.mean(acc_NN_ts), 'std_accuracy_NN':np.std(acc_NN_ts),\n",
        "                          'mean_f1score_NN':np.mean(f1_NN_ts) , 'std_f1score_NN':np.std(f1_NN_ts), 'confusion_NN':mean_conf(conf_NN_ts),\n",
        "                          'mean_accuracy_SVM':np.mean(acc_SVM_ts), 'std_accuracy_SVM':np.std(acc_SVM_ts),\n",
        "                          'mean_f1score_SVM':np.mean(f1_SVM_ts), 'std_f1score_SVM':np.std(f1_SVM_ts), 'confusion_SVM':mean_conf(conf_SVM_ts),\n",
        "                          'mean_accuracy_LR':np.mean(acc_LR_ts), 'std_accuracy_LR':np.std(acc_LR_ts),\n",
        "                          'mean_f1score_LR':np.mean(f1_LR_ts), 'std_f1score_LR':np.std(f1_LR_ts), 'confusion_LR':mean_conf(conf_LR_ts),\n",
        "                          'mean_accuracy_MLP':np.mean(acc_MLP_ts), 'std_accuracy_MLP':np.std(acc_MLP_ts),\n",
        "                          'mean_f1score_MLP':np.mean(f1_MLP_ts), 'std_f1score_MLP':np.std(f1_MLP_ts), 'confusion_MLP':mean_conf(conf_MLP_ts)}\n",
        "    \n",
        "    # store best parametrs\n",
        "    par_to_store = {'features_number':f'{i}','Nearest Neighbor':best_par_NN,\n",
        "                    'Support Vector Machine':best_par_SVM, 'Logistic Regresion':best_par_LR,\n",
        "                    'Multi-layer Perceptron':best_par_MLP}\n",
        "    \n",
        "    train_metrics = train_metrics.append(train_data_to_store, ignore_index = True)\n",
        "    test_metrics = test_metrics.append(test_data_to_store, ignore_index = True)\n",
        "    parameters = parameters.append(par_to_store, ignore_index=True)\n",
        "    \n",
        "    # reducing number of features for next iteration\n",
        "    i-=1\n",
        "\n",
        "# save the data as a csv file\n",
        "train_metrics.to_csv('/content/drive/MyDrive/output/features_variation_t2_train.csv')  \n",
        "test_metrics.to_csv('/content/drive/MyDrive/output/features_variation_t2_test.csv') \n",
        "parameters.to_csv('/content/drive/MyDrive/output/best_parameters_t2.csv')\n"
      ],
      "metadata": {
        "id": "YYE0wYM0fXtN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}